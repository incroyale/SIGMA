{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed071cd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3327606804.py, line 133)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_125756\\3327606804.py\"\u001b[1;36m, line \u001b[1;32m133\u001b[0m\n\u001b[1;33m    zip_filename = 'C:\\Users\\Lenovo\\Downloads\\img_align_celeba.zip'\u001b[0m\n\u001b[1;37m                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing\n",
    "from helper_train import train_gan_v1\n",
    "from helper_utils import set_deterministic, set_all_seeds\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "class DCGAN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=100,\n",
    "                 num_feat_maps_gen=64, num_feat_maps_dis=64,\n",
    "                 color_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, num_feat_maps_gen * 8,\n",
    "                               kernel_size=4, stride=1, padding=0,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_gen * 8),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size if latent_dim=100: num_feat_maps_gen*8 x 4 x 4\n",
    "            #\n",
    "            nn.ConvTranspose2d(num_feat_maps_gen * 8, num_feat_maps_gen * 4,\n",
    "                               kernel_size=4, stride=2, padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_gen * 4),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size if latent_dim=100: num_feat_maps_gen*4 x 8 x 8\n",
    "            #\n",
    "            nn.ConvTranspose2d(num_feat_maps_gen * 4, num_feat_maps_gen * 2,\n",
    "                               kernel_size=4, stride=2, padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_gen * 2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size if latent_dim=100: num_feat_maps_gen*2 x 16 x 16\n",
    "            #\n",
    "            nn.ConvTranspose2d(num_feat_maps_gen * 2, num_feat_maps_gen,\n",
    "                               kernel_size=4, stride=2, padding=1,\n",
    "                               bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_gen),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size if latent_dim=100: num_feat_maps_gen x 32 x 32\n",
    "            #\n",
    "            nn.ConvTranspose2d(num_feat_maps_gen, color_channels,\n",
    "                               kernel_size=4, stride=2, padding=1,\n",
    "                               bias=False),\n",
    "            #\n",
    "            # size: color_channels x 64 x 64\n",
    "            #\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.discriminator = nn.Sequential(\n",
    "            #\n",
    "            # input size color_channels x image_height x image_width\n",
    "            #\n",
    "            nn.Conv2d(color_channels, num_feat_maps_dis,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size: num_feat_maps_dis x 32 x 32\n",
    "            #\n",
    "            nn.Conv2d(num_feat_maps_dis, num_feat_maps_dis * 2,\n",
    "                      kernel_size=4, stride=2, padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_dis * 2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size: num_feat_maps_dis*2 x 16 x 16\n",
    "            #\n",
    "            nn.Conv2d(num_feat_maps_dis * 2, num_feat_maps_dis * 4,\n",
    "                      kernel_size=4, stride=2, padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_dis * 4),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size: num_feat_maps_dis*4 x 8 x 8\n",
    "            #\n",
    "            nn.Conv2d(num_feat_maps_dis * 4, num_feat_maps_dis * 8,\n",
    "                      kernel_size=4, stride=2, padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(num_feat_maps_dis * 8),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #\n",
    "            # size: num_feat_maps_dis*8 x 4 x 4\n",
    "            #\n",
    "            nn.Conv2d(num_feat_maps_dis * 8, 1,\n",
    "                      kernel_size=4, stride=1, padding=0),\n",
    "\n",
    "            # size: 1 x 1 x 1\n",
    "            nn.Flatten(),\n",
    "\n",
    "        )\n",
    "\n",
    "    def generator_forward(self, z):\n",
    "        img = self.generator(z)\n",
    "        return img\n",
    "\n",
    "    def discriminator_forward(self, img):\n",
    "        logits = model.discriminator(img)\n",
    "        return logits\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    multiprocessing.freeze_support()\n",
    "    ############################# SETTINGS ##################################\n",
    "    # Device\n",
    "    CUDA_DEVICE_NUM = 1\n",
    "    DEVICE = torch.device(f'cuda:{CUDA_DEVICE_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Hyperparameters\n",
    "    RANDOM_SEED = 42\n",
    "    GENERATOR_LEARNING_RATE = 0.0002\n",
    "    DISCRIMINATOR_LEARNING_RATE = 0.0002\n",
    "\n",
    "    NUM_EPOCHS = int(input(\"Enter number of epochs: \"))\n",
    "    BATCH_SIZE = 128\n",
    "\n",
    "    IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS = 64, 64, 3\n",
    "\n",
    "    set_deterministic\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "    zip_filename = \"C:\\Users\\Lenovo\\Downloads\\img_align_celeba.zip\"\n",
    "    extracted_folder = 'data/'\n",
    "    os.makedirs(extracted_folder, exist_ok=True)\n",
    "    zip_filepath = os.path.join(os.getcwd(), zip_filename)\n",
    "    with zipfile.ZipFile(zip_filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_folder)\n",
    "\n",
    "\n",
    "    def get_dataloaders_celeba(batch_size, num_workers=0,\n",
    "                               train_transforms=None,\n",
    "                               test_transforms=None):\n",
    "        \"\"\"\n",
    "        Change path for the image_folder. Directory structure: given_path -> classes -> all images\n",
    "        Don't directly point to directory with images.\n",
    "        \"\"\"\n",
    "        if train_transforms is None:\n",
    "            train_transforms = transforms.ToTensor()\n",
    "\n",
    "        if test_transforms is None:\n",
    "            test_transforms = transforms.ToTensor()\n",
    "\n",
    "        # Define the full dataset\n",
    "        full_dataset = datasets.ImageFolder(root=r'C:\\Users\\Lenovo\\PycharmProjects\\DCGAN\\SIGMA\\external_ouput\\faces\\data',\n",
    "                                            transform=train_transforms)\n",
    "\n",
    "        # Create data loader for the full dataset\n",
    "        data_loader = DataLoader(dataset=full_dataset,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=num_workers,\n",
    "                                 shuffle=True)\n",
    "\n",
    "        return data_loader\n",
    "\n",
    "\n",
    "    ################################# Dataset Pre Processing #################################\n",
    "    custom_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.CenterCrop((160, 160)),\n",
    "        torchvision.transforms.Resize([IMAGE_HEIGHT, IMAGE_WIDTH]),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    data_loader = get_dataloaders_celeba(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        train_transforms=custom_transforms,\n",
    "        test_transforms=custom_transforms,\n",
    "        num_workers=4)\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = torch.device('cuda:0')  # Use the first GPU (index 0)\n",
    "    else:\n",
    "        DEVICE = torch.device('cpu')  # If CUDA is not available, use CPU\n",
    "\n",
    "    set_all_seeds(RANDOM_SEED)\n",
    "\n",
    "    model = DCGAN()\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optim_gen = torch.optim.Adam(model.generator.parameters(), betas=(0.5, 0.999), lr=GENERATOR_LEARNING_RATE)\n",
    "    optim_discr = torch.optim.Adam(model.discriminator.parameters(), betas=(0.5, 0.999), lr=DISCRIMINATOR_LEARNING_RATE)\n",
    "    log_dict = train_gan_v1(num_epochs=NUM_EPOCHS, model=model, optimizer_gen=optim_gen, optimizer_discr=optim_discr,\n",
    "                            latent_dim=100,\n",
    "                            device=DEVICE, train_loader=data_loader, logging_interval=100,\n",
    "                            save_model='gan_celeba_01.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429d773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
